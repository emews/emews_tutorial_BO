---
title: "BO-EMEWS example"
output:
  html_document:
    df_print: paged
---

```{r}
library(TSBatchBO)
library(hetGP)
library(mvtnorm)
```


## Sample simulation function

```{r}

foo <- function(X)
 {
  if(is.null(nrow(X))) X <- matrix(X, nrow=1)
  m <- 8.6928
  s <- 2.4269
  x1 <- 4*X[,1] - 2
  x2 <- 4*X[,2] - 2
  a <- 1 + (x1 + x2 + 1)^2 * 
    (19 - 14*x1 + 3*x1^2 - 14*x2 + 6*x1*x2 + 3*x2^2)
  b <- 30 + (2*x1 - 3*x2)^2 * 
    (18 - 32*x1 + 12*x1^2 + 48*x2 - 36*x1*x2 + 27*x2^2)
  f <- log(a*b)
  f <- (f - m)/s + rnorm(1, sd = 0.1)
  return(f)
 }
```

## Utility function
```{r}
## a function to scale parameters to native bounds
#' scaling function
#'
#' @param x a matrix
#' @param lb lower bound, a vector of length ncol(x)
#' @param ub upper bound, a vector of length ncol(x)
#'
#' @return a matrix

to_native <- function(x, lb, ub){
  x_native <- array(NA, dim = dim(x))
  for (i in 1:ncol(x)){
    x_native[, i] <- lb[i] + x[, i] * (ub[i] - lb[i])
  }
  return(x_native)
}
```


## Initial design and search space

We set a lattice grid in the unit box, which the 
minimizer of `foo` will be searched over. 20 points among those 1000 are randomly
picked to evaluate to start the optimization.

```{r, fig.align='center', fig.height=5, fig.width=5}
xx <- seq(0, 1, length.out = 30)
Xgrid <- as.matrix(expand.grid(xx, xx))

n1 <- 10
N <- nrow(Xgrid)
init_id <- sample(N, n1)

col_vec <- rep("grey", N)
col_vec[init_id] <- "red"
pairs(Xgrid, col = col_vec, cex = 0.8, labels = c(expression(x[1]), expression(x[2])))

## evaluate 
X <- Xgrid[init_id, ]
# rescale to the native input scale
X_native <- to_native(X, lb = c(0, 0), ub = c(1, 1))
Y <- apply(X_native, 1, foo)

## save the current best and keep track of it
f_best <- c()
X_best <- matrix(NA, nrow = 0, ncol = 2)

f_best <- c(f_best, min(Y))
X_best <- rbind(X_best, X[which.min(Y), ])
cat(">> iter = ", 0, "| current best value = ", 
                f_best[1], "at x1 = ", X_best[1, 1], ", x2 = ", X_best[1, 2], "\n")
```

## Bayesian Optimization

```{r}
nstep <- 30 # times the optimization loop should run
npoints <- 10 # size of the batch evaluation in each iteration

## fit GP on initial data
gp <- hetGP::mleHomGP(X, Y, covtype = "Gaussian")

for (i in 1:nstep){
  
  ## next batch of points for evaluation based on Thompson sampling
  X_new <- TS_npoints(model = gp, npoints = npoints, Xgrid = Xgrid)
  
  ## evaluate
  X_new_native <- to_native(X_new, lb = c(0, 0), ub = c(1, 1))
  Y_new <- apply(X_new, 1, foo)
  
  ## update GP
  f <- update(gp, X_new, Y_new)
  
  ## store the new best
  X <- rbind(X, X_new)
  Y <- c(Y, Y_new)
  f_best <- c(f_best, min(Y))
  X_best <- rbind(X_best, X[which.min(Y), ])
  cat(">> iter = ", i, "| current best value = ", 
                  f_best[i+1], "at x1 = ", X_best[i+1, 1], ", x2 = ", X_best[i+1, 2], "\n")
}
```

Now we look at the result after 30 iteration


```{r, fig.align='center', fig.height=5, fig.width=5}
plot(X[,1], X[,2], col = rgb(1, 0, 0, alpha = seq(0.5, 1, length.out = nrow(X))), main = "sequential evaluations")
```
```{r, fig.align='center', fig.height=5, fig.width=5}
plot(X_best[,1], X_best[,2], col = rgb(1, 0, 0, alpha = seq(0.5, 1, length.out = nrow(X))), main = "Best solution progression",
     xlim = c(0, 1), ylim = c(0, 1))
```