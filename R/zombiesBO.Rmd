

```{r}
library(hetGP)
library(gridExtra)
library(jsonlite)
library(reticulate)
library(EQ.SQL)
source('~/argonne/projects/data_assimilation/emews_tutorial_BO/R/helpers.R')
```

## Bayesian Optimization of the Zombies model

This notebook contains a complete worked example of finding the optimal parameters of a simple simulation model using EMEWS. 

### Generate grid and initial design

Our goal is to find the combination of **zombie step size** and **human step size** that results in the highest human survival rate in the simulation. For this design, we consider **30 human step sizes between 1 and 3** and **30 zombie step sizes between 0.1 and 1** (for 900 possible parameter combinations). We select 5 parameter combinations to initialize the BO procedure, shown below. 

```{r}
# Set up unit grid (the BO procedure needs input values between 0 and 1)
xx <- seq(0, 1, length.out = 30)
Xgrid <- expand.grid(xx, xx)
Xgrid <- as.matrix(Xgrid)

# Scale the grid to the desired step sizes
Xgrid_native <- to_native(Xgrid, lb = c(0.1, 1), ub = c(1, 3))

# Index of initial points (chosen for a well-spaced design)
init_ids <- c(218, 234, 466, 698, 714)

# Plot
plot(Xgrid_native[,1], Xgrid_native[,2],
     col = rgb(0.5, 0.5, 0.5, 0.2),
     pch = 16, cex = 0.5,
     xlab = "Zombie Step Size",
     ylab = "Human Step Size",
     main = "Initial Design")

points(Xgrid_native[init_ids,1], Xgrid_native[init_ids,2], pch = 16, cex = 1)
```

### Setup EMEWS DB
Next, we start the EMEWS database, local task queues, and worker pools. 

```{r}
config_file =  "algo_cfg.yaml"
params = parse_yaml_cfg(config_file)
exp_id = 1
eqsql <- init_eqsql(python_path = params$python_path)

db_started <- FALSE
pool <- NULL
task_queue <- NULL

eqsql <- init_eqsql(python_path = params$python_path)

eqsql$db_tools$start_db(params$db_path)
db_started <- TRUE

task_queue <- init_task_queue(eqsql, params$db_host, params$db_user, params$db_port,
                              params$db_name)

if (!task_queue$are_queues_empty()) {
    print("WARNING: task input / output queues are not empty. Aborting run")
    task_queue$clear_queues()
} else {
    pool_params <- eqsql$worker_pool$cfg_file_to_dict(params$pool_cfg_file)
    pool <- eqsql$worker_pool$start_local_pool(params$worker_pool_id, params$pool_launch_script,
                                                exp_id, pool_params)

    task_type <- params$task_type
}
```
### Initialize Bayesian Optimization procedure

Because the Zombies model is **stochastic** (meaning that for the same combination of parameters, different random seeds will result in different outcomes), our optimization procedure will proceed as follows. First, we will evalute our initial design points for 3 different random seeds (known a **replicates**). We fit a **Gaussian Process (GP)** model on these initial 15 points using [hetGP](https://cran.r-project.org/web/packages/hetGP/vignettes/hetGP_vignette.pdf), which is designed to handle replicates well). Based on the predicted mean surface and covariance of this GP model, we will select additional points to evaluate following the [Thompson Sampling](https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf) procedure. We will evaluate these points one replicate at a time; if a point that has already been evaluated is selected again, we will re-evaluate it with a new random seed.


```{r}
# Set the computational budget/total number of simulations we want to run
budget <- 50

# Set the number of points we will sample each iteration
nts <- 10

# Random seeds for replicates
seeds <- sample(1:1000, 100, replace = FALSE)

# Set number of initial replicates and subtract from budget
init_reps <- 3
budget <- budget - length(init_ids) * init_reps

# Setup counters for tracking which new replicates to evaluate
id_counter <- as.list(rep(0, nrow(Xgrid)))
```


### Submit initial payload to EMEWS

We are now ready to run the simulation with EMEWS. In the `../swift/eqsql_worker_pool.swift` file, we define a function `update_params_t` that tells us the format EMEWS expects to submit a job: 

```
params = {'human_step_size': steps[1], 'zombie_step_size': steps[0],
          'counts_file': counts_file, 'random.seed': int(steps[2])}
```

We've defined the function `generate_inputs` in `helpers.R` that takes the entire grid, the index locations of parameters to evaluate, the counter, and the random seeds and generates matrices in the in required format (in their native units with the associated random seed), in addition to a scaled version to use for the GP. 

We convert these matrices to JSON and submit them as payloads to the EMEWS task queue. Once the jobs are complete, we retrieve the results and scale them for appropriate use in the GP.

```{r}

# Generate inputs in required format
inputs <- generate_inputs(Xgrid, rep(init_ids, init_reps), id_counter, seeds)
X <- as.matrix(inputs$X)
Xnative <- inputs$Xnative

# Submit initial inputs to EMEWS and retrieve results
fts <- apply(Xnative, 1, function(a) {
    payload <- toJSON(as.list(a), auto_unbox = TRUE)
    submission <- task_queue$submit_task(exp_id, task_type, payload)
    # return the future task
    submission[[2]]
})

results <- as_completed(task_queue, fts, function(ft) {
    list(
        eq_task_id = ft$eq_task_id,                # Capture the task ID
        data = fromJSON(ft$result()[[2]])          # The task result
    )
})

# Sort them to align with inputs
eq_ids <- sapply(results$f_results, function(x) x$eq_task_id)
eq_ids <- unlist(eq_ids)
Y <- sapply(results$f_results[order(eq_ids)], function(x) x$data)

Y <- log(Y)
ymean <- mean(Y)
ystd <- sd(Y)
Y <- (Y - ymean) / ystd
```


#### Fit GP on initial design
To begin the optimization process, we begin by fitting a GP model to these initial points. The parameters we've specified in the model were selected after some intial experimentation. After fitting the model, we predict the mean surface and variance over the entire grid of potential parameters and plot them. We are storing the plots in a list to display them nicely together at the end.

```{r}
gp <- mleHetGP(X, Y, noiseControl = list(g_bounds = c(1e-6, .1)), upper=c(100,100))
plots <- list()

p <- plot_gp_mean(gp, Xgrid, X, ymean, ystd, title="Initial design")
plots[[1]] <- p
p
```
We see that the predicted surface shows more human survivors toward the origin, but also much higher variance. The Thompson Sampling (TS) optimization procedure draws samples from a multivariate normal distrubtion with mean and covariance set to the values from the GP predictions. We find the location of the maximum value for each of these samples and run the simulation at these points. 

#### First TS iteration

To demonstrate, we perform the TS after the initial design, which selects the parameters shown below. 

```{r}
# Thompson sample to find the next points to evaluate
best_ids <- TS_npoints(gp, min(nts, budget), Xgrid)

# Create inputs in required format
new_inputs = generate_inputs(Xgrid, best_ids, id_counter, seeds)
Xnew <- new_inputs$X
Xnative_new <- new_inputs$Xnative

# Plot new locations
plot(Xgrid_native[,1], Xgrid_native[,2],
     col = rgb(0.5, 0.5, 0.5, 0.2),
     pch = 16, cex = 0.5,
     xlab = "Zombie Step Size",
     ylab = "Human Step Size",
     main = "Initial Design")

points(Xnative_new[,1], Xnative_new[,2], pch = 16, cex = 1)
```
Next, we evaluate the Zombies model for these new parameters by submitting them to the EMEWS task queue and update the budget. We then refit the GP with all locations that have currently been evaluated and plot the updated predicted surface. Darker circles indicate that a location has been selected multiple times.

```{r}
new_inputs = generate_inputs(Xgrid, best_ids, id_counter, seeds)
Xnew <- new_inputs$X
Xnative_new <- new_inputs$Xnative

# Submit initial inputs to EMEWS and retrieve results
fts <- apply(Xnative_new, 1, function(a) {
    payload <- toJSON(as.list(a), auto_unbox = TRUE)
    submission <- task_queue$submit_task(exp_id, task_type, payload)
    # return the future task
    submission[[2]]
})

results <- as_completed(task_queue, fts, function(ft) {
    list(
        eq_task_id = ft$eq_task_id,                # Capture the task ID
        data = fromJSON(ft$result()[[2]])          # The task result
    )
})

budget = budget - nts

# Sort them to align with inputs
eq_ids <- sapply(results$f_results, function(x) x$eq_task_id)
eq_ids <- unlist(eq_ids)
Ynew <- sapply(results$f_results[order(eq_ids)], function(x) x$data)

Ynew = log(Ynew)
Ynew = (Ynew - ymean)/ystd

X <- rbind(X, Xnew)
Y <- c(Y, Ynew)
  
gp <- mleHetGP(X, Y, noiseControl = list(g_bounds = c(1e-6, .1)), upper=c(100,100))
p <- plot_gp_mean(gp, Xgrid, X, ymean, ystd, title=paste("Iteration", 2))
plots[[2]] <- p
```


```{r}
# exhaust budget
j <- 3
while (budget > 0){
  best_ids <- TS_npoints(gp, min(nts, budget), Xgrid)
  new_inputs = generate_inputs(Xgrid, best_ids, id_counter, seeds)
  Xnew <- new_inputs$X
  Xnative_new <- new_inputs$Xnative
  
  
  # Submit initial inputs to EMEWS and retrieve results
  fts <- apply(Xnative_new, 1, function(a) {
      payload <- toJSON(as.list(a), auto_unbox = TRUE)
      submission <- task_queue$submit_task(exp_id, task_type, payload)
      # return the future task
      submission[[2]]
  })
  
  results <- as_completed(task_queue, fts, function(ft) {
      list(
          eq_task_id = ft$eq_task_id,                # Capture the task ID
          data = fromJSON(ft$result()[[2]])          # The task result
      )
  })
  
  budget = budget - nts
  
  # Sort them to align with inputs
  eq_ids <- sapply(results$f_results, function(x) x$eq_task_id)
  eq_ids <- unlist(eq_ids)
  Ynew <- sapply(results$f_results[order(eq_ids)], function(x) x$data)
  
  Ynew = log(Ynew)
  Ynew = (Ynew - ymean)/ystd
  
  X <- rbind(X, Xnew)
  Y <- c(Y, Ynew)
  
  gp <- mleHetGP(X, Y, noiseControl = list(g_bounds = c(1e-6, .1)), upper=c(100,100))
  p <- plot_gp_mean(gp, Xgrid, X, ymean, ystd, title=paste("Iteration", j-1))
  plots[[j]] <- p
  j <- j+1
}

do.call(grid.arrange, c(plots, ncol = 5))
```


```{r}
if (!is.null(task_queue)) task_queue$close()
if (!is.null(pool)) pool$cancel()
if (db_started) eqsql$db_tools$stop_db(params$db_path)
```


